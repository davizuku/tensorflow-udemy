{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with some California Census Data, we'll be trying to use various features of an individual to predict what class of income they belogn in (>50k or <=50k). \n",
    "\n",
    "Here is some information about the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Column Name</th>\n",
    "<th>Type</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>age</td>\n",
    "<td>Continuous</td>\n",
    "<td>The age of the individual</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>workclass</td>\n",
    "<td>Categorical</td>\n",
    "<td>The type of employer the  individual has (government,  military, private, etc.).</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>fnlwgt</td>\n",
    "<td>Continuous</td>\n",
    "<td>The number of people the census  takers believe that observation  represents (sample weight). This  variable will not be used.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education</td>\n",
    "<td>Categorical</td>\n",
    "<td>The highest level of education  achieved for that individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education_num</td>\n",
    "<td>Continuous</td>\n",
    "<td>The highest level of education in  numerical form.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>marital_status</td>\n",
    "<td>Categorical</td>\n",
    "<td>Marital status of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>occupation</td>\n",
    "<td>Categorical</td>\n",
    "<td>The occupation of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>relationship</td>\n",
    "<td>Categorical</td>\n",
    "<td>Wife, Own-child, Husband,  Not-in-family, Other-relative,  Unmarried.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>race</td>\n",
    "<td>Categorical</td>\n",
    "<td>White, Asian-Pac-Islander,  Amer-Indian-Eskimo, Other, Black.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>gender</td>\n",
    "<td>Categorical</td>\n",
    "<td>Female, Male.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_gain</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital gains recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_loss</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital Losses recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>hours_per_week</td>\n",
    "<td>Continuous</td>\n",
    "<td>Hours worked per week.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>native_country</td>\n",
    "<td>Categorical</td>\n",
    "<td>Country of origin of the  individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>income</td>\n",
    "<td>Categorical</td>\n",
    "<td>\"&gt;50K\" or \"&lt;=50K\", meaning  whether the person makes more  than \\$50,000 annually.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow the Directions in Bold. If you get stuck, check out the solutions lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in the census_data.csv data with pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "census = pd.read_csv('./census_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.581647</td>\n",
       "      <td>10.080679</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>40.437456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.640433</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.347429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  education_num  capital_gain  capital_loss  hours_per_week\n",
       "count  32561.000000   32561.000000  32561.000000  32561.000000    32561.000000\n",
       "mean      38.581647      10.080679   1077.648844     87.303830       40.437456\n",
       "std       13.640433       2.572720   7385.292085    402.960219       12.347429\n",
       "min       17.000000       1.000000      0.000000      0.000000        1.000000\n",
       "25%       28.000000       9.000000      0.000000      0.000000       40.000000\n",
       "50%       37.000000      10.000000      0.000000      0.000000       40.000000\n",
       "75%       48.000000      12.000000      0.000000      0.000000       45.000000\n",
       "max       90.000000      16.000000  99999.000000   4356.000000       99.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 13)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TensorFlow won't be able to understand strings as labels, you'll need to use pandas .apply() method to apply a custom function that converts them to 0s and 1s. This might be hard if you aren't very familiar with pandas, so feel free to take a peek at the solutions for this part.**\n",
    "\n",
    "** Convert the Label column to 0s and 1s instead of strings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age [39 50 38 53 28]\n",
      "workclass [' State-gov' ' Self-emp-not-inc' ' Private' ' Federal-gov' ' Local-gov']\n",
      "education [' Bachelors' ' HS-grad' ' 11th' ' Masters' ' 9th']\n",
      "education_num [13  9  7 14  5]\n",
      "marital_status [' Never-married' ' Married-civ-spouse' ' Divorced'\n",
      " ' Married-spouse-absent' ' Separated']\n",
      "occupation [' Adm-clerical' ' Exec-managerial' ' Handlers-cleaners' ' Prof-specialty'\n",
      " ' Other-service']\n",
      "relationship [' Not-in-family' ' Husband' ' Wife' ' Own-child' ' Unmarried']\n",
      "race [' White' ' Black' ' Asian-Pac-Islander' ' Amer-Indian-Eskimo' ' Other']\n",
      "gender [' Male' ' Female']\n",
      "capital_gain [ 2174     0 14084  5178  5013]\n",
      "capital_loss [   0 2042 1408 1902 1573]\n",
      "hours_per_week [40 13 16 45 50]\n",
      "native_country [' United-States' ' Cuba' ' Jamaica' ' India' ' ?']\n",
      "income_bracket [' <=50K' ' >50K']\n"
     ]
    }
   ],
   "source": [
    "for c in census.columns:\n",
    "    print(c, census[c].unique()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "census['target_income'] = pd.Categorical(census.income_bracket).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.income_bracket.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Train Test Split on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = census.target_income\n",
    "census = census.drop(['target_income', 'income_bracket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    census, \n",
    "    label,\n",
    "    test_size = 0.33, \n",
    "    random_state = 101\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>35</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25762</th>\n",
       "      <td>60</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17851</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12116</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>4064</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass      education  education_num  \\\n",
       "941     35            Private        HS-grad              9   \n",
       "25762   60   Self-emp-not-inc   Some-college             10   \n",
       "3987    37            Private      Bachelors             13   \n",
       "17851   31            Private   Some-college             10   \n",
       "12116   43            Private   Some-college             10   \n",
       "\n",
       "            marital_status          occupation relationship  \\\n",
       "941     Married-civ-spouse   Machine-op-inspct      Husband   \n",
       "25762   Married-civ-spouse     Exec-managerial      Husband   \n",
       "3987    Married-civ-spouse       Other-service      Husband   \n",
       "17851   Married-civ-spouse        Adm-clerical      Husband   \n",
       "12116   Married-civ-spouse        Craft-repair      Husband   \n",
       "\n",
       "                      race gender  capital_gain  capital_loss  hours_per_week  \\\n",
       "941                  Black   Male             0             0              40   \n",
       "25762                White   Male             0             0              40   \n",
       "3987    Asian-Pac-Islander   Male             0             0              30   \n",
       "17851                White   Male             0             0              40   \n",
       "12116                White   Male          4064             0              38   \n",
       "\n",
       "       native_country  \n",
       "941     United-States  \n",
       "25762   United-States  \n",
       "3987            China  \n",
       "17851   United-States  \n",
       "12116   United-States  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "941      0\n",
       "25762    1\n",
       "3987     0\n",
       "17851    0\n",
       "12116    0\n",
       "Name: target_income, dtype: int8"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Feature Columns for tf.esitmator\n",
    "\n",
    "** Take note of categorical vs continuous values! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'education', 'education_num', 'marital_status',\n",
       "       'occupation', 'relationship', 'race', 'gender', 'capital_gain',\n",
       "       'capital_loss', 'hours_per_week', 'native_country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'education', 'education_num', 'marital_status',\n",
       "       'occupation', 'relationship', 'race', 'gender', 'capital_gain',\n",
       "       'capital_loss', 'hours_per_week', 'native_country', 'income_bracket'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import Tensorflow **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Create the tf.feature_columns for the categorical values. Use vocabulary lists or just use hash buckets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age 73\n",
      "workclass 9\n",
      "education 16\n",
      "education_num 16\n",
      "marital_status 7\n",
      "occupation 15\n",
      "relationship 6\n",
      "race 5\n",
      "gender 2\n",
      "capital_gain 119\n",
      "capital_loss 92\n",
      "hours_per_week 94\n",
      "native_country 42\n"
     ]
    }
   ],
   "source": [
    "for c in census.columns:\n",
    "    print(c, census[c].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('workclass', 10),\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('education', 20),\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('marital_status', 10),\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('occupation', 20),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('relationship', ['Wife', 'Own-child', 'Husband', 'Not-in-family', 'Other-relative', 'Unmarried']),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('race', ['White', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other', 'Black']),\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('gender', ['Female', 'Male']),\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('native_country', 50),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the continuous feature_columns for the continuous values using numeric_column **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continuous_features = [\n",
    "    tf.feature_column.numeric_column('age'),\n",
    "    tf.feature_column.numeric_column('education_num'),\n",
    "    tf.feature_column.numeric_column('capital_gain'),\n",
    "    tf.feature_column.numeric_column('capital_loss'),\n",
    "    tf.feature_column.numeric_column('hours_per_week'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Put all these variables into a single list with the variable name feat_cols **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_cols = categorical_features + continuous_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Input Function\n",
    "\n",
    "** Batch_size is up to you. But do make sure to shuffle!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x = X_train, \n",
    "    y = y_train, \n",
    "    batch_size = 100, \n",
    "    num_epochs = None, \n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your model with tf.estimator\n",
    "\n",
    "**Create a LinearClassifier.(If you want to use a DNNClassifier, keep in mind you'll need to create embedded columns out of the cateogrical feature that use strings, check out the previous lecture on this for more info.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/7f/kl6zxp_50ddcw8xr42yvrpfm0000gn/T/tmpnsocjcdt\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/7f/kl6zxp_50ddcw8xr42yvrpfm0000gn/T/tmpnsocjcdt', '_save_summary_steps': 100, '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_session_config': None, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None}\n"
     ]
    }
   ],
   "source": [
    "linearModel = tf.estimator.LinearClassifier(\n",
    "    feature_columns = feat_cols,\n",
    "    n_classes = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_HashedCategoricalColumn(key='workclass', hash_bucket_size=10, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='education', hash_bucket_size=20, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='marital_status', hash_bucket_size=10, dtype=tf.string),\n",
       " _HashedCategoricalColumn(key='occupation', hash_bucket_size=20, dtype=tf.string),\n",
       " _VocabularyListCategoricalColumn(key='relationship', vocabulary_list=('Wife', 'Own-child', 'Husband', 'Not-in-family', 'Other-relative', 'Unmarried'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
       " _VocabularyListCategoricalColumn(key='race', vocabulary_list=('White', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other', 'Black'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
       " _VocabularyListCategoricalColumn(key='gender', vocabulary_list=('Female', 'Male'), dtype=tf.string, default_value=-1, num_oov_buckets=0),\n",
       " _HashedCategoricalColumn(key='native_country', hash_bucket_size=50, dtype=tf.string)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnn_categorical_features = []\n",
    "for cf in categorical_features:\n",
    "    if hasattr(cf, 'hash_bucket_size'):\n",
    "        emb = tf.feature_column.embedding_column(\n",
    "            cf, \n",
    "            cf.hash_bucket_size\n",
    "        )\n",
    "    else:\n",
    "        emb = tf.feature_column.embedding_column(\n",
    "            cf,\n",
    "            len(cf.vocabulary_list)\n",
    "        )\n",
    "    dnn_categorical_features.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/7f/kl6zxp_50ddcw8xr42yvrpfm0000gn/T/tmpzv8hwxjm\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/7f/kl6zxp_50ddcw8xr42yvrpfm0000gn/T/tmpzv8hwxjm', '_save_summary_steps': 100, '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_session_config': None, '_tf_random_seed': 1, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None}\n"
     ]
    }
   ],
   "source": [
    "dnn_feat_cols = dnn_categorical_features + continuous_features\n",
    "dnnModel = tf.estimator.DNNClassifier(\n",
    "    hidden_units = [ 20 ] * 3, \n",
    "    feature_columns = dnn_feat_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train your model on the data, for at least 5000 steps. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/7f/kl6zxp_50ddcw8xr42yvrpfm0000gn/T/tmpnsocjcdt/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 69.3147\n",
      "INFO:tensorflow:global_step/sec: 104.473\n",
      "INFO:tensorflow:step = 101, loss = 278.105 (0.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.484\n",
      "INFO:tensorflow:step = 201, loss = 61.8264 (0.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.271\n",
      "INFO:tensorflow:step = 301, loss = 154.323 (0.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.71\n",
      "INFO:tensorflow:step = 401, loss = 1013.53 (0.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.365\n",
      "INFO:tensorflow:step = 501, loss = 106.537 (0.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.636\n",
      "INFO:tensorflow:step = 601, loss = 572.219 (0.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.729\n",
      "INFO:tensorflow:step = 701, loss = 99.7765 (0.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.222\n",
      "INFO:tensorflow:step = 801, loss = 123.912 (0.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.667\n",
      "INFO:tensorflow:step = 901, loss = 138.999 (0.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.828\n",
      "INFO:tensorflow:step = 1001, loss = 101.034 (0.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.702\n",
      "INFO:tensorflow:step = 1101, loss = 112.461 (0.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.531\n",
      "INFO:tensorflow:step = 1201, loss = 146.192 (0.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.5858\n",
      "INFO:tensorflow:step = 1301, loss = 130.935 (1.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.966\n",
      "INFO:tensorflow:step = 1401, loss = 217.855 (0.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.828\n",
      "INFO:tensorflow:step = 1501, loss = 50.0546 (0.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.138\n",
      "INFO:tensorflow:step = 1601, loss = 291.738 (0.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.135\n",
      "INFO:tensorflow:step = 1701, loss = 135.767 (0.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.889\n",
      "INFO:tensorflow:step = 1801, loss = 81.8652 (0.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.275\n",
      "INFO:tensorflow:step = 1901, loss = 43.3167 (0.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.48\n",
      "INFO:tensorflow:step = 2001, loss = 130.987 (0.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.968\n",
      "INFO:tensorflow:step = 2101, loss = 129.045 (0.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.847\n",
      "INFO:tensorflow:step = 2201, loss = 49.2487 (0.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.388\n",
      "INFO:tensorflow:step = 2301, loss = 39.2698 (0.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.025\n",
      "INFO:tensorflow:step = 2401, loss = 57.0179 (0.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.693\n",
      "INFO:tensorflow:step = 2501, loss = 31.3037 (0.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.747\n",
      "INFO:tensorflow:step = 2601, loss = 43.7815 (0.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.983\n",
      "INFO:tensorflow:step = 2701, loss = 89.0971 (0.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.109\n",
      "INFO:tensorflow:step = 2801, loss = 36.3976 (0.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.339\n",
      "INFO:tensorflow:step = 2901, loss = 86.8925 (0.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 107\n",
      "INFO:tensorflow:step = 3001, loss = 69.1818 (0.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.092\n",
      "INFO:tensorflow:step = 3101, loss = 34.6165 (0.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.945\n",
      "INFO:tensorflow:step = 3201, loss = 140.664 (0.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.47\n",
      "INFO:tensorflow:step = 3301, loss = 44.3513 (0.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.881\n",
      "INFO:tensorflow:step = 3401, loss = 57.9026 (0.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.672\n",
      "INFO:tensorflow:step = 3501, loss = 35.8222 (0.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.35\n",
      "INFO:tensorflow:step = 3601, loss = 296.844 (0.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.419\n",
      "INFO:tensorflow:step = 3701, loss = 44.0945 (0.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.957\n",
      "INFO:tensorflow:step = 3801, loss = 77.4767 (0.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.334\n",
      "INFO:tensorflow:step = 3901, loss = 41.07 (0.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.434\n",
      "INFO:tensorflow:step = 4001, loss = 80.1064 (0.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.601\n",
      "INFO:tensorflow:step = 4101, loss = 89.5831 (0.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.824\n",
      "INFO:tensorflow:step = 4201, loss = 32.7582 (0.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.214\n",
      "INFO:tensorflow:step = 4301, loss = 90.2003 (0.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.664\n",
      "INFO:tensorflow:step = 4401, loss = 100.452 (0.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.732\n",
      "INFO:tensorflow:step = 4501, loss = 59.8063 (0.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.695\n",
      "INFO:tensorflow:step = 4601, loss = 33.0525 (0.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.871\n",
      "INFO:tensorflow:step = 4701, loss = 55.6285 (0.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.673\n",
      "INFO:tensorflow:step = 4801, loss = 139.994 (0.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.189\n",
      "INFO:tensorflow:step = 4901, loss = 343.548 (0.876 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/7f/kl6zxp_50ddcw8xr42yvrpfm0000gn/T/tmpnsocjcdt/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 44.5411.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x12037e5c0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearModel.train(train_input_fn, steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/7f/kl6zxp_50ddcw8xr42yvrpfm0000gn/T/tmpzv8hwxjm/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 2001.57\n",
      "INFO:tensorflow:global_step/sec: 101.225\n",
      "INFO:tensorflow:step = 101, loss = 41.706 (0.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.732\n",
      "INFO:tensorflow:step = 201, loss = 32.6319 (0.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.046\n",
      "INFO:tensorflow:step = 301, loss = 38.0829 (0.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.48\n",
      "INFO:tensorflow:step = 401, loss = 24.8358 (0.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.883\n",
      "INFO:tensorflow:step = 501, loss = 35.2721 (0.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.624\n",
      "INFO:tensorflow:step = 601, loss = 28.9604 (0.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.32\n",
      "INFO:tensorflow:step = 701, loss = 45.6234 (0.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.427\n",
      "INFO:tensorflow:step = 801, loss = 38.545 (0.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.028\n",
      "INFO:tensorflow:step = 901, loss = 33.7385 (0.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.008\n",
      "INFO:tensorflow:step = 1001, loss = 29.363 (0.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.839\n",
      "INFO:tensorflow:step = 1101, loss = 33.0209 (0.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.1247\n",
      "INFO:tensorflow:step = 1201, loss = 27.705 (1.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.8\n",
      "INFO:tensorflow:step = 1301, loss = 35.5277 (0.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.352\n",
      "INFO:tensorflow:step = 1401, loss = 39.6916 (0.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.37\n",
      "INFO:tensorflow:step = 1501, loss = 28.1404 (0.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.005\n",
      "INFO:tensorflow:step = 1601, loss = 36.7779 (0.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.623\n",
      "INFO:tensorflow:step = 1701, loss = 33.0839 (0.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.734\n",
      "INFO:tensorflow:step = 1801, loss = 34.7715 (0.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.542\n",
      "INFO:tensorflow:step = 1901, loss = 35.3554 (0.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.461\n",
      "INFO:tensorflow:step = 2001, loss = 30.9503 (0.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.243\n",
      "INFO:tensorflow:step = 2101, loss = 45.0817 (0.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.715\n",
      "INFO:tensorflow:step = 2201, loss = 29.9059 (0.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.973\n",
      "INFO:tensorflow:step = 2301, loss = 29.4211 (0.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.598\n",
      "INFO:tensorflow:step = 2401, loss = 48.8344 (0.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.442\n",
      "INFO:tensorflow:step = 2501, loss = 28.3509 (0.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.372\n",
      "INFO:tensorflow:step = 2601, loss = 32.1885 (0.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.924\n",
      "INFO:tensorflow:step = 2701, loss = 34.8715 (0.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.933\n",
      "INFO:tensorflow:step = 2801, loss = 30.9779 (0.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.278\n",
      "INFO:tensorflow:step = 2901, loss = 31.6384 (0.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.742\n",
      "INFO:tensorflow:step = 3001, loss = 32.1079 (0.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.905\n",
      "INFO:tensorflow:step = 3101, loss = 31.5085 (0.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.059\n",
      "INFO:tensorflow:step = 3201, loss = 25.2922 (0.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.124\n",
      "INFO:tensorflow:step = 3301, loss = 31.6902 (0.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.538\n",
      "INFO:tensorflow:step = 3401, loss = 26.2381 (0.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.107\n",
      "INFO:tensorflow:step = 3501, loss = 31.8364 (0.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.4\n",
      "INFO:tensorflow:step = 3601, loss = 37.775 (0.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.165\n",
      "INFO:tensorflow:step = 3701, loss = 38.7447 (0.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.3463\n",
      "INFO:tensorflow:step = 3801, loss = 35.5736 (1.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.483\n",
      "INFO:tensorflow:step = 3901, loss = 27.9382 (0.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.903\n",
      "INFO:tensorflow:step = 4001, loss = 30.3456 (0.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.857\n",
      "INFO:tensorflow:step = 4101, loss = 25.4465 (0.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.247\n",
      "INFO:tensorflow:step = 4201, loss = 31.588 (0.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.691\n",
      "INFO:tensorflow:step = 4301, loss = 37.9334 (0.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.28\n",
      "INFO:tensorflow:step = 4401, loss = 26.1482 (0.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.961\n",
      "INFO:tensorflow:step = 4501, loss = 28.0382 (0.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.128\n",
      "INFO:tensorflow:step = 4601, loss = 41.5711 (0.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.821\n",
      "INFO:tensorflow:step = 4701, loss = 39.3716 (0.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.526\n",
      "INFO:tensorflow:step = 4801, loss = 30.5433 (0.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.147\n",
      "INFO:tensorflow:step = 4901, loss = 39.0181 (0.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.756\n",
      "INFO:tensorflow:step = 5001, loss = 33.9075 (0.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.352\n",
      "INFO:tensorflow:step = 5101, loss = 26.7186 (0.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.095\n",
      "INFO:tensorflow:step = 5201, loss = 24.8495 (0.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.034\n",
      "INFO:tensorflow:step = 5301, loss = 23.9357 (0.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.327\n",
      "INFO:tensorflow:step = 5401, loss = 34.8211 (0.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.594\n",
      "INFO:tensorflow:step = 5501, loss = 24.8155 (0.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.655\n",
      "INFO:tensorflow:step = 5601, loss = 28.4642 (0.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.337\n",
      "INFO:tensorflow:step = 5701, loss = 29.7311 (0.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.856\n",
      "INFO:tensorflow:step = 5801, loss = 26.4975 (0.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.52\n",
      "INFO:tensorflow:step = 5901, loss = 34.7127 (0.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.023\n",
      "INFO:tensorflow:step = 6001, loss = 50.3836 (0.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.586\n",
      "INFO:tensorflow:step = 6101, loss = 29.7858 (0.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.764\n",
      "INFO:tensorflow:step = 6201, loss = 38.2867 (0.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.639\n",
      "INFO:tensorflow:step = 6301, loss = 32.0432 (0.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.249\n",
      "INFO:tensorflow:step = 6401, loss = 28.4718 (0.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.933\n",
      "INFO:tensorflow:step = 6501, loss = 29.949 (0.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.47\n",
      "INFO:tensorflow:step = 6601, loss = 33.0929 (0.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.463\n",
      "INFO:tensorflow:step = 6701, loss = 31.6171 (0.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.967\n",
      "INFO:tensorflow:step = 6801, loss = 28.3648 (0.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.578\n",
      "INFO:tensorflow:step = 6901, loss = 37.73 (0.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.755\n",
      "INFO:tensorflow:step = 7001, loss = 21.3595 (0.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.53\n",
      "INFO:tensorflow:step = 7101, loss = 31.6581 (0.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.73\n",
      "INFO:tensorflow:step = 7201, loss = 32.4624 (0.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.515\n",
      "INFO:tensorflow:step = 7301, loss = 40.4359 (0.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.922\n",
      "INFO:tensorflow:step = 7401, loss = 25.34 (0.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.265\n",
      "INFO:tensorflow:step = 7501, loss = 35.8185 (0.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.356\n",
      "INFO:tensorflow:step = 7601, loss = 25.2058 (0.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.748\n",
      "INFO:tensorflow:step = 7701, loss = 27.9699 (0.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.895\n",
      "INFO:tensorflow:step = 7801, loss = 34.0971 (0.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.882\n",
      "INFO:tensorflow:step = 7901, loss = 36.7073 (0.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.796\n",
      "INFO:tensorflow:step = 8001, loss = 33.8942 (0.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.47\n",
      "INFO:tensorflow:step = 8101, loss = 22.9947 (0.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.519\n",
      "INFO:tensorflow:step = 8201, loss = 27.5524 (0.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.794\n",
      "INFO:tensorflow:step = 8301, loss = 32.342 (0.871 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 116.861\n",
      "INFO:tensorflow:step = 8401, loss = 28.1763 (0.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.958\n",
      "INFO:tensorflow:step = 8501, loss = 34.6208 (0.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.155\n",
      "INFO:tensorflow:step = 8601, loss = 32.3669 (0.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.172\n",
      "INFO:tensorflow:step = 8701, loss = 38.0892 (0.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.434\n",
      "INFO:tensorflow:step = 8801, loss = 32.1122 (0.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.379\n",
      "INFO:tensorflow:step = 8901, loss = 27.0036 (0.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.011\n",
      "INFO:tensorflow:step = 9001, loss = 29.6537 (0.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.026\n",
      "INFO:tensorflow:step = 9101, loss = 36.0277 (0.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.875\n",
      "INFO:tensorflow:step = 9201, loss = 51.164 (0.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.98\n",
      "INFO:tensorflow:step = 9301, loss = 34.4751 (0.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.653\n",
      "INFO:tensorflow:step = 9401, loss = 37.2378 (0.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.944\n",
      "INFO:tensorflow:step = 9501, loss = 34.1518 (0.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.124\n",
      "INFO:tensorflow:step = 9601, loss = 56.0155 (0.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.1591\n",
      "INFO:tensorflow:step = 9701, loss = 32.211 (1.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.4264\n",
      "INFO:tensorflow:step = 9801, loss = 37.3232 (1.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.5735\n",
      "INFO:tensorflow:step = 9901, loss = 33.669 (1.049 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /var/folders/7f/kl6zxp_50ddcw8xr42yvrpfm0000gn/T/tmpzv8hwxjm/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 27.8245.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1206b44a8>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnModel.train(train_input_fn, steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "** Create a prediction input function. Remember to only supprt X_test data and keep shuffle=False. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    X_test, \n",
    "    batch_size = len(X_test), \n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use model.predict() and pass in your input function. This will produce a generator of predictions, which you can then transform into a list, with list() **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/7f/kl6zxp_50ddcw8xr42yvrpfm0000gn/T/tmpnsocjcdt/model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "linearPredictions = linearModel.predict(pred_input_fn)\n",
    "linearPredictions = list(linearPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/7f/kl6zxp_50ddcw8xr42yvrpfm0000gn/T/tmpzv8hwxjm/model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "dnnPredictions = dnnModel.predict(pred_input_fn)\n",
    "dnnPredictions = list(dnnPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Each item in your list will look like this: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([0]),\n",
       " 'classes': array([b'0'], dtype=object),\n",
       " 'logistic': array([ 0.13777165], dtype=float32),\n",
       " 'logits': array([-1.83392262], dtype=float32),\n",
       " 'probabilities': array([ 0.86222839,  0.13777164], dtype=float32)}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearPredictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([0]),\n",
       " 'classes': array([b'0'], dtype=object),\n",
       " 'logistic': array([ 0.2315159], dtype=float32),\n",
       " 'logits': array([-1.1997714], dtype=float32),\n",
       " 'probabilities': array([ 0.76848412,  0.23151588], dtype=float32)}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnPredictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a list of only the class_ids key values from the prediction list of dictionaries, these are the predictions you will use to compare against the real y_test values. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearLabels = [ p['class_ids'][0] for p in linearPredictions ]\n",
    "linearLabels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnLabels = [ p['class_ids'][0] for p in dnnPredictions ]\n",
    "dnnLabels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import classification_report from sklearn.metrics and then see if you can figure out how to use it to easily get a full report of your model's performance on the test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.94      0.90      8161\n",
      "          1       0.75      0.55      0.64      2585\n",
      "\n",
      "avg / total       0.84      0.85      0.84     10746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, linearLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.93      0.91      8161\n",
      "          1       0.73      0.62      0.67      2585\n",
      "\n",
      "avg / total       0.85      0.85      0.85     10746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, dnnLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90      7436\n",
      "          1       0.70      0.59      0.64      2333\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
